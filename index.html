<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Memleak by ssthappy</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/github-light.css">
    <meta name="viewport" content="width=device-width">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
    <div class="wrapper">
      <header>
        <h1>Memleak</h1>
        <p>Dynamically validating static memory leak warnings</p>

        <p class="view"><a href="https://github.com/ssthappy/memleak">View the Project on GitHub <small>ssthappy/memleak</small></a></p>


        <ul>
          <li><a href="https://github.com/ssthappy/memleak/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/ssthappy/memleak/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/ssthappy/memleak">View On <strong>GitHub</strong></a></li>
        </ul>
      </header>
      <section>
        <p>This site presents our memory leak validation tool and experiment data.</p>
		<p>SEG (Software Engineering Group) , Nanjing University</p>

<h3>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction</h3>

<p>Memory leaks have significant impact on software availability, performance and security. Static analysis has been widely used to find memory leaks in C/C++ programs. Although a static analysis is able to find all potential leaks in a program, it often reports a great number of false warnings. Manually validating these warnings is a daunting task, which significantly limits the practicality of the analysis. So we develop a novel dynamic technique that automatically validates and categorizes such warnings to unleash the power of static memory leak detectors. Our technique analyzes each warning that contains information regarding the leaking allocation site and the leaking path, generates test cases to cover the leaking path, and tracks objects created by the leaking allocation site. Eventually, warnings are classified into four categories: MUST-LEAK, LIKELY-NOT-LEAK, BLOAT, and MAY-LEAK.</p>

<h3>
<a id="warning-classification" class="anchor" href="#warning-classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>Warning classification</h3>

<p>Warnings are classified into four categories: <b>MUST-LEAK</b>, <b>LIKELY-NOT-LEAK</b>, <b>BLOAT</b>, and <b>MAY-LEAK</b>.</p>
<p>Warnings in MUST-LEAK are guaranteed by our analysis to be true leaks. Warnings in LIKELY-NOT-LEAK are highly likely to be false warnings. Although we cannot provide any formal guarantee that they are not leaks, we have high confidence that this is the case. Warnings in BLOAT are also not likely to be leaks but they should be fixed to improve performance. Using our approach, the developer's manual verification effort needs to be focused only on warnings in the category MAY-LEAK, which is often much smaller than the original set.</p>

<h3>
<a id="experiment" class="anchor" href="#experiment" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experiment</h3>

<p>Our instrumentation was performed using the <a href="http://sourceforge.net/projects/cil/">CIL</a> instrumentation framework. The <a href="https://github.com/jburnim/crest">CREST</a> concolic testing engine was modified to perform the path-guided test case generation. The static memory leak detector used in our experiments was HP Fortify version 3.2.</p>

<h4>
<a id="Experimental Subjects" class="anchor" href="#benchmark" aria-hidden="true"><span class="octicon octicon-link"></span></a>Experimental Subjects</h4>
<p>We perform our first experiment using a set of programs from the Siemens and the <a href="http://www.gnu.org/software/coreutils/">coreutils</a> benchmark suites. These programs are relatively small and it is thus easy for us to understand their implementation logic to manually verify our classification results. To increase the number of static analysis warnings for each program, we manually injected both true and false leaks. </br>The programs are as follows:</p>
<table>
<tr><td>Program</td>	<td>Lines</td>	<td>Description</td></tr>
<tr><td>replace</td>	<td>563</td>	<td>Replace pattern</td></tr>
<tr><td>print_tokens</td>	<td>726</td>	<td>Lexical analysis</td></tr>
<tr><td>print_tokens2</td>	<td>569</td>	<td>Lexical analysis</td></tr>
<tr><td>tcas</td>	<td>173</td>	<td>Collision avoidance</td></tr>
<tr><td>wc</td>	<td>802</td>	<td>Print newline, word, and byte counts for each file</td></tr>
<tr><td>cat</td>	<td>785</td>	<td>Concatenate and write files</td></tr>
<tr><td>head</td>	<td>1063</td>	<td>Output the first part of files</td></tr>
<tr><td>tr</td>	<td>1949</td>	<td>Translate or delete characters</td></tr>
<tr><td>expand</td>	<td>433</td>	<td>Convert tabs to spaces</td></tr>
<tr><td>unexpand</td>	<td>535</td>	<td>Convert spaces to tabs</td></tr>
</table>
<p>The second experiment includes a case study on the use of our tool to validate leaks for a large-scale application (i.e.,texinfo-4.33).</p>
<h4>
<a id="result" class="anchor" href="#result" aria-hidden="true"><span class="octicon octicon-link"></span></a>Result</h4>
<p>Experiment 1:</p>
<table>
<tr><td>Program</td>	<td>#L</td>	<td>#W</td>	<td>#S</td>	<td>#Must</td>	<td>#LNL</td>	<td>#B</td>	<td>#May</td>	<td>#F</td></tr>
<tr><td>replace</td>	<td>563</td>	<td>18</td>	<td>3444</td>	<td>5</td>	<td>3</td>	<td>4</td>	<td>6</td>	<td>0</td></tr>
<tr><td>print_tokens</td>	<td>726</td>	<td>22</td>	<td>17383</td>	<td>8</td>	<td>4</td>	<td>6</td>	<td>4</td>	<td>0</td></tr>
<tr><td>print_tokens2</td>	<td>569</td>	<td>29</td>	<td>16943</td>	<td>8</td>	<td>7</td>	<td>9</td>	<td>5</td>	<td>0</td></tr>
<tr><td>tcas</td>	<td>173</td>	<td>8</td>	<td>54</td>	<td>1</td>	<td>4</td>	<td>1</td>	<td>2</td>	<td>0</td></tr>
<tr><td>wc</td>	<td>802</td>	<td>8</td>	<td>6000</td>	<td>2</td>	<td>2</td>	<td>2</td>	<td>2</td>	<td>0</td></tr>
<tr><td>cat</td>	<td>785</td>	<td>8</td>	<td>4002</td>	<td>2</td>	<td>1</td>	<td>2</td>	<td>3</td>	<td>0</td></tr>
<tr><td>head</td>	<td>1063</td>	<td>18</td>	<td>5007</td>	<td>4</td>	<td>6</td>	<td>2</td>	<td>6</td>	<td>0</td></tr>
<tr><td>tr</td>	<td>1949</td>	<td>32</td>	<td>37281</td>	<td>11</td>	<td>8</td>	<td>8</td>	<td>5</td>	<td>0</td></tr>
<tr><td>expand</td>	<td>433</td>	<td>6</td>	<td>3854</td>	<td>1</td>	<td>1</td>	<td>2</td>	<td>2</td>	<td>0</td></tr>
<tr><td>unexpand</td>	<td>535</td>	<td>6</td>	<td>3996</td>	<td>1</td>	<td>1</td>	<td>2</td>	<td>2</td>	<td>0</td></tr>
</table>
<p>#L: Lines of code; </br>#W: Numbers of warnings reported by Fortify; </br>#S: Numbers of test cases generated by the path-guided concolic testing</br>#Must: MUST-LEAK; #LNL: LIKELY-NOT-LEAK; #B: BLOAT; #May: MAY-LEAK; </br>#F: False Classifications</p>

<p>Experiment 2:</p>
<p>Fortify reports a total of 91 warnings for texinfo. Our analysis has successfully classified 70 of them. For the rest 21 of the warnings, no test case can be generated by CREST to exercise their reported path fragments and thus they are classified as MAY-LEAK. This is primarily because the path constraints for these warnings are too complicated to solve. Among the 70 warnings that are precisely classified, the numbers of warnings in MUST-LEAK, LIKELY-NOT-LEAK, and BLOAT are, respectively, 69, 1, and 0.

<h3>
<a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true"><span class="octicon octicon-link"></span></a>Support or Contact</h3>

<p>If you have any questions or suggestions, please contact us.</p>
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/ssthappy">ssthappy</a></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>
